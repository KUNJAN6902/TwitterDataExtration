{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_API.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "clrzxf-N9hnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tweepy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXyWKPqT9mxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "\n",
        "#Add your credentials here\n",
        "twitter_keys = {\n",
        "        'consumer_key':        'X',\n",
        "        'consumer_secret':     'X',\n",
        "        'access_token_key':    'X',\n",
        "        'access_token_secret': 'X'\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIbNCnu69qqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setup access to API\n",
        "auth = tweepy.OAuthHandler(twitter_keys['consumer_key'], twitter_keys['consumer_secret'])\n",
        "auth.set_access_token(twitter_keys['access_token_key'], twitter_keys['access_token_secret'])\n",
        "\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56KStRdX9u0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = []\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime, timedelta\n",
        "from pytz import timezone\n",
        " \n",
        "gmt = timezone('Asia/Kolkata')\n",
        "last_hour_date_time = datetime.now(gmt) - timedelta(hours = 150)\n",
        "\n",
        "for tweet in tweepy.Cursor(api.search, q=\"#covid OR #covid19 OR #covid-19 OR #corona OR #StayHome OR #StaySafe OR #coronavirus -filter:retweets\", \n",
        "                           count=5000,  since=last_hour_date_time.strftime('%Y-%m-%d %H'), tweet_mode='extended', lang=\"en\").items(1000):\n",
        "\n",
        "#for tweet in tweepy.Cursor(api.search, q=\"#covid OR #covid19 OR #covid-19 OR #corona OR #StayHome OR #StaySafe OR #coronavirus -filter:retweets\", \n",
        "#                           count=5000, since='2020-04-06', until='2020-04-07', tweet_mode='extended', lang=\"en\").items(1000):\n",
        "    data = [tweet.created_at, tweet.full_text, tweet.user._json['name'], tweet.user._json['screen_name'], tweet.user._json['id'], tweet.user._json['location'], \n",
        "            tweet.user._json['followers_count'], parse(tweet.user._json['created_at']).strftime(\"%d-%m-%Y\"), tweet.user._json['statuses_count'], tweet.user._json['friends_count'],\n",
        "            tweet.user._json['listed_count'], tweet.user._json['favourites_count']]\n",
        "\n",
        "    data = tuple(data)\n",
        "    tweets.append(data)\n",
        "    continue\n",
        "\t\n",
        "df = pd.DataFrame(tweets, columns = ['tweet_time', 'tweet_text', 'username', 'user_screenname', 'userid', 'location', 'followers_count',\n",
        "                                     'twtr_joined_on', 'statuses_count', 'friends_count', 'listed_count', 'favourites_count'])\n",
        "\n",
        "print(\"df ready : \", df.shape )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y0iJ-zrE766",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "!pip install tweet-preprocessor\n",
        "import preprocessor as p\n",
        "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.SMILEY, p.OPT.EMOJI)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmDdTOdQIZNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "cleantweetsNOPunct = []\n",
        "import string\n",
        "table = str.maketrans('','', string.punctuation)\n",
        "\n",
        "for tweet in df['tweet_text']:\n",
        "    try:\n",
        "        tweet = p.clean(tweet)\n",
        "        #tokenize\n",
        "        words2 = word_tokenize(tweet.lower())\n",
        "        #remove puncts\n",
        "        words3 = [w.translate(table) for w in words2]\n",
        "        cleantweetsNOPunct.append((\" \".join(words3)).strip())\n",
        "    except:\n",
        "        cleantweetsNOPunct.append(tweet)\n",
        "        continue\n",
        "\n",
        "print(len(cleantweetsNOPunct))\n",
        "\n",
        "df['clean_Tweet_NoPunct'] = cleantweetsNOPunct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kiD4aNFIRXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filename = \"Covid19_Tweets\" + str(datetime.now(gmt).strftime('%Y-%m-%d %H:%M')) + \".csv\"\n",
        "filename = \"Covid19_Tweets\" + str(last_hour_date_time).replace(\" \", \"\") + \".csv\"\n",
        "\n",
        "df.to_csv(filename, index=False)\n",
        "print(filename + \" stored as csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qipivdJdH9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFjfTpSYdHvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code to map extracted Location form Twitter to proper Country Name\n",
        "!pip install pycountry\n",
        "import pycountry\n",
        "import pandas as pd\n",
        "\n",
        "database = pd.read_csv(filename)\n",
        "database.shape\n",
        "\n",
        "from geopy.geocoders import Nominatim\n",
        "geolocator = Nominatim(user_agent='kunjan6902@yahoo.in')\n",
        "wordlist = []\n",
        "countrylist = []\n",
        "\n",
        "for place in countries:\n",
        "    try:\n",
        "        location = geolocator.geocode(place)\n",
        "        wordlist.extend(str(location).split(','))\n",
        "        countrylist.append(wordlist[-1])\n",
        "    except:\n",
        "        countrylist.append('none')\n",
        "        continue\n",
        "\n",
        "database['mapped_country'] = countrylist\n",
        "\n",
        "df.to_csv(\"mapped_countries.csv\", index=False) \n",
        "print(\"mapped_countries stored as csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9pLuS2bd-gI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code to translate different country names written in native languages into English\n",
        "!pip install googletrans\n",
        "from googletrans import Translator\n",
        "import pandas as pd\n",
        "\n",
        "translated = []\n",
        "\n",
        "database = pd.read_csv(\"sample_data/mapped_countries.csv\")\n",
        "\n",
        "for cntr_to_translate in database['location']:\n",
        "    try:\n",
        "        # REINITIALIZE THE API\n",
        "        translator = Translator()\n",
        "        #print(cntr_to_translate)\n",
        "        done = translator.translate(cntr_to_translate)\n",
        "        translated.append(done.text)\n",
        "    except:\n",
        "        translated.append('none')\n",
        "        continue\n",
        "\n",
        "database['trans_country'] = translated\n",
        "\n",
        "df.to_csv(\"trnsltd_countries.csv\", index=False) \n",
        "print(\"trnsltd_countries stored as csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY7k_ygzfwn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code to download Retweets\n",
        "retweets = []\n",
        "count = 1\n",
        "\n",
        "for tweet in tweepy.Cursor(api.search, q=\"#covid OR #covid19 OR #covid-19 OR #corona OR #StayHome OR #StaySafe OR #coronavirus filter:retweets\",\n",
        "                            count=5000,  since='2020-04-08', tweet_mode='extended', lang=\"en\").items(100),\n",
        "    data = [tweet.created_at, tweet.full_text, tweet.user._json['name'], tweet.user._json['screen_name'], tweet.user._json['id'], tweet.user._json['location'],\n",
        "            tweet.user._json['followers_count'], parse(tweet.user._json['created_at']).strftime(\"%d-%m-%Y\"), tweet.user._json['statuses_count'], tweet.user._json['friends_count'],\n",
        "            tweet.user._json['listed_count'], tweet.user._json['favourites_count']],\n",
        "    data = tuple(data)\n",
        "    retweets.append(data)\n",
        "    except tweepy.TweepError as e:\n",
        "        print(e.reason)\n",
        "        continue\n",
        "    except StopIteration:\n",
        "        break\n",
        "        \n",
        "df = pd.DataFrame(retweets, columns = ['tweet_time', 'tweet_text', 'username', 'user_screenname', 'userid', 'location', 'followers_count',\n",
        "                                    'twtr_joined_on', 'statuses_count', 'friends_count', 'listed_count', 'favourites_count'])\n",
        "\n",
        "df.to_csv(\"Covid19_Retweets_all.csv\", index=False),\n",
        "print(\"Covid19_Retweets_all stored as csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}